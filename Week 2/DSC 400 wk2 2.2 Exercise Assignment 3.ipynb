{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **2.2 Exercise Assignment 3**\n",
    "# Michael J. Montana\n",
    "# College of Science and Tecnology, Bellevue University\n",
    "# DSC400: Big Data, Technology, and Algorithms\n",
    "# Professor Shawn Hermans\n",
    "# June 18 2023"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MapReduce Patterns in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Assignment 3\n",
    "\n",
    "This assignment will introduce you to the MapReduce programming paradigm using Python and Apache Spark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Global imports\n",
    "\n",
    "from collections import defaultdict\n",
    "import string\n",
    "from operator import add\n",
    "from functools import reduce\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You will use the following text snippets in parts of your assignment. These values were generated from https://slipsum.com/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text1 = \"\"\"\n",
    "    Well, the way they make shows is, they make one show. \n",
    "    That show's called a pilot. \n",
    "    Then they show that show to the people who make shows, \n",
    "    and on the strength of that one show they decide \n",
    "    if they're going to make more shows. Some pilots \n",
    "    get picked and become television programs. \n",
    "    Some don't, become nothing. \n",
    "    She starred in one of the ones that became nothing.\n",
    "\"\"\"\n",
    "\n",
    "text2 = \"\"\"\n",
    "    You think water moves fast? You should see ice. \n",
    "    It moves like it has a mind. \n",
    "    Like it knows it killed the world once and got a taste for murder. \n",
    "    After the avalanche, it took us a week to climb out. \n",
    "    Now, I don't know exactly when we turned on each other, \n",
    "    but I know that seven of us survived the slide... \n",
    "    and only five made it out. Now we took an oath, that I'm breaking now. \n",
    "    We said we'd say it was the snow that killed the other two, but it wasn't. \n",
    "    Nature is lethal but it doesn't hold a candle to man.\n",
    "\"\"\"\n",
    "\n",
    "text3 = \"\"\"\n",
    "    Now that we know who you are, I know who I am. I'm not a mistake! \n",
    "    It all makes sense! In a comic, you know how you can tell who the arch-villain's going to be? \n",
    "    He's the exact opposite of the hero. And most times they're friends, like you and me! \n",
    "    I should've known way back when... You know why, David? Because of the kids. \n",
    "    They called me Mr Glass.\n",
    "\"\"\"\n",
    "\n",
    "text4 = \"\"\"\n",
    "    Your bones don't break, mine do. That's clear. \n",
    "    Your cells react to bacteria and viruses differently than mine. \n",
    "    You don't get sick, I do. That's also clear. \n",
    "    But for some reason, you and I react the exact same way to water. \n",
    "    We swallow it too fast, we choke. We get some in our lungs, we drown. \n",
    "    However unreal it may seem, we are connected, you and I. \n",
    "    We're on the same curve, just on opposite ends.\n",
    "\"\"\"\n",
    "\n",
    "documents = [text1, text2, text3, text4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Assignment 3.1\n",
    " \n",
    "In the first part of the assignment, you implement map and reduce functions that count the occurrences of words in a collection of documents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Assignment 3.1.a\n",
    "\n",
    "In this part, you will implement a function that takes a document and outputs word/count tuple pairs. You will then apply that function across multiple documents using Python's built-in `map` function. \n",
    "\n",
    "The `map` function applies a function to every item in an input list of values. Technically, the input can be any Python iterable, but for the sake of simplicity, assume it is a list of values.  The primary reason to use the `map` function is that it is simple to parallelize its execution across multiple processes and computers. \n",
    "\n",
    "The following is a simple example of using Python's `multiprocessing` library to run a `map` function in five parallel processes. \n",
    "\n",
    "```python\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def square_number(x):\n",
    "    return x*x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(5) as p:\n",
    "        values = [1, 2, 3, 4, 5]\n",
    "        print(p.map(square_number, values))\n",
    "```\n",
    "\n",
    "The above code prints the following result to standard output.\n",
    "\n",
    "```\n",
    "[1, 4, 9, 16, 25]\n",
    "```\n",
    "\n",
    "This is the same example that uses Python's built-in `map` function. This function does not take advantage of parallel execution. \n",
    "\n",
    "```python\n",
    "def square_number(x):\n",
    "    return x*x\n",
    "\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "results = map(square_number, numbers)\n",
    "print(list(results))\n",
    "```\n",
    "\n",
    "A partially implemented version of the `word_count_map_function` is included below. Fill in the missing details. The `remove_punctuation` is provided as a way of removing punctuation from the input text. You can use this function in the implementation of the `word_count_map_function`."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <font color=orange>**TODO**</font>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Simple function to remove punctuation from text\n",
    "\n",
    "    :param text: text to remove punctuation from\n",
    "    :return: text with punctuation removed\n",
    "    \"\"\"\n",
    "    return ''.join([\n",
    "        character\n",
    "        for character in text\n",
    "        if character not in string.punctuation\n",
    "    ])\n",
    "\n",
    "def word_count_map_function(text: str) -> list[tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Simple map function that takes text and outputs tuples\n",
    "    of words and counts\n",
    "    \n",
    "    :param text: text to convert into word/count tuples\n",
    "    :return: A list of tuples with word and count\n",
    "    \"\"\"\n",
    "    # TODO: Implement the word count map function\n",
    "\n",
    "    # Step 1: Remove punctuation from text\n",
    "    # Step 2: Convert text to lower case\n",
    "    # Step 3: Split the text by spaces to convert into words\n",
    "    # Step 4: Return a list containing a dictionary of words and counts\n",
    "\n",
    "    words = [\n",
    "        word.lower().strip()\n",
    "        for word in remove_punctuation(text).split(' ')\n",
    "    ]\n",
    "\n",
    "    # This line is here as a placeholder. Replace with your own code\n",
    "    word_count_pairs = [\n",
    "        (word, 1)\n",
    "        for word in words\n",
    "        if word\n",
    "    ]\n",
    "    return word_count_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "[('a', 1),\n ('and', 1),\n ('and', 1),\n ('became', 1),\n ('become', 1),\n ('become', 1),\n ('called', 1),\n ('decide', 1),\n ('dont', 1),\n ('get', 1),\n ('going', 1),\n ('if', 1),\n ('in', 1),\n ('is', 1),\n ('make', 1),\n ('make', 1),\n ('make', 1),\n ('make', 1),\n ('more', 1),\n ('nothing', 1)]"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1_words = word_count_map_function(text1)\n",
    "text1_words.sort()\n",
    "text1_top20=text1_words[:20]\n",
    "text1_top20"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following is example output of the function applied to `text1`\n",
    "```python\n",
    ">>> word_count_map_function(text1)\n",
    "\n",
    "[('well', 1),\n",
    " ('the', 1),\n",
    " ('way', 1),\n",
    " ('they', 1),\n",
    " ('make', 1),\n",
    " ('shows', 1),\n",
    "    ...\n",
    " ('ones', 1),\n",
    " ('that', 1),\n",
    " ('became', 1),\n",
    " ('nothing', 1)]\n",
    "```\n",
    "\n",
    "Note: The count for each of these examples is *1* since the mapper did not perform a reduce task (i.e. combine key/value pairs). In practice,  mappers may perform an internal reduce before sending along data to the global reduce task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Assignment 3.1.b\n",
    "\n",
    "A MapReduce program usually contains multiple steps. Each *map* function runs in parallel and outputs a key/value pair. In the case of the word count task, the word is the key and the count is the value. The *reduce* function sorts each of the *map* outputs by the key (i.e. word) and then combine the results. The *reduce* phase is more computationally expensive as it involves sorting and combining data from multiple *map* functions. \n",
    "\n",
    "In this part, you will implement a function that combines the word/count pairs from the previous step. You will then apply that function across all of the *map* outputs using Python's *reduce* function. Previously, *reduce* was included in Python's built-in library, but now it is included in the *functools* library.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following example uses the *reduce* function to combine two lists.  \n",
    "\n",
    "```python\n",
    "list1 = [1, 2, 3, 4, 5]\n",
    "list2 = [6, 7, 8, 9, 10]\n",
    "\n",
    "lists = [list1, list2]\n",
    "\n",
    "def merge_lists_reduce_function(x, y):\n",
    "    return x + y\n",
    "\n",
    "merged_values = reduce(merge_lists_reduce_function, lists)\n",
    "merged_values\n",
    "```\n",
    "This produces the output:\n",
    "\n",
    "```\n",
    "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "```\n",
    "\n",
    "We can use the *reduce* function a second time to add the numbers in the combined list. \n",
    "\n",
    "```\n",
    "reduce(add, merged_values)\n",
    "```\n",
    "This returns the result:\n",
    "\n",
    "```\n",
    "55\n",
    "```\n",
    "\n",
    "A partially implemented version of the `word_count_reduce_function` is included below. Fill in the missing details."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <font color=orange>**TODO**</font>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def merge_lists_reduce_function(x,y):\n",
    "    return x+y\n",
    "\n",
    "def word_count_reduce_function(key_value_pairs):\n",
    "    result = defaultdict(int)\n",
    "    # TODO: Implement code to return list containing word/count pairs\n",
    "    for word, count in key_value_pairs:\n",
    "        result[word] += count\n",
    "    return sorted(result.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following code uses the functions defined previously to run the MapReduce job. The `counted_words_dict` variable should be a dictionary where the words are the keys and the total count for each word are the values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[('a', 7),\n ('after', 1),\n ('all', 1),\n ('also', 1),\n ('am', 1),\n ('an', 1),\n ('and', 9),\n ('archvillains', 1),\n ('are', 2),\n ('avalanche', 1),\n ('back', 1),\n ('bacteria', 1),\n ('be', 1),\n ('became', 1),\n ('because', 1),\n ('become', 2),\n ('bones', 1),\n ('break', 1),\n ('breaking', 1),\n ('but', 4),\n ('called', 2),\n ('can', 1),\n ('candle', 1),\n ('cells', 1),\n ('choke', 1),\n ('clear', 2),\n ('climb', 1),\n ('comic', 1),\n ('connected', 1),\n ('curve', 1),\n ('david', 1),\n ('decide', 1),\n ('differently', 1),\n ('do', 2),\n ('doesnt', 1),\n ('dont', 4),\n ('drown', 1),\n ('each', 1),\n ('ends', 1),\n ('exact', 2),\n ('exactly', 1),\n ('fast', 2),\n ('five', 1),\n ('for', 2),\n ('friends', 1),\n ('get', 3),\n ('glass', 1),\n ('going', 2),\n ('got', 1),\n ('has', 1),\n ('hero', 1),\n ('hes', 1),\n ('hold', 1),\n ('how', 1),\n ('however', 1),\n ('i', 8),\n ('ice', 1),\n ('if', 1),\n ('im', 2),\n ('in', 3),\n ('is', 2),\n ('it', 12),\n ('just', 1),\n ('kids', 1),\n ('killed', 2),\n ('know', 6),\n ('known', 1),\n ('knows', 1),\n ('lethal', 1),\n ('like', 3),\n ('lungs', 1),\n ('made', 1),\n ('make', 4),\n ('makes', 1),\n ('man', 1),\n ('may', 1),\n ('me', 2),\n ('mind', 1),\n ('mine', 2),\n ('mistake', 1),\n ('more', 1),\n ('most', 1),\n ('moves', 2),\n ('mr', 1),\n ('murder', 1),\n ('nature', 1),\n ('not', 1),\n ('nothing', 2),\n ('now', 4),\n ('oath', 1),\n ('of', 5),\n ('on', 4),\n ('once', 1),\n ('one', 3),\n ('ones', 1),\n ('only', 1),\n ('opposite', 2),\n ('other', 2),\n ('our', 1),\n ('out', 2),\n ('people', 1),\n ('picked', 1),\n ('pilot', 1),\n ('pilots', 1),\n ('programs', 1),\n ('react', 2),\n ('reason', 1),\n ('said', 1),\n ('same', 2),\n ('say', 1),\n ('see', 1),\n ('seem', 1),\n ('sense', 1),\n ('seven', 1),\n ('she', 1),\n ('should', 1),\n ('shouldve', 1),\n ('show', 4),\n ('shows', 4),\n ('sick', 1),\n ('slide', 1),\n ('snow', 1),\n ('some', 4),\n ('starred', 1),\n ('strength', 1),\n ('survived', 1),\n ('swallow', 1),\n ('taste', 1),\n ('television', 1),\n ('tell', 1),\n ('than', 1),\n ('that', 8),\n ('thats', 2),\n ('the', 15),\n ('then', 1),\n ('they', 5),\n ('theyre', 2),\n ('think', 1),\n ('times', 1),\n ('to', 7),\n ('too', 1),\n ('took', 2),\n ('turned', 1),\n ('two', 1),\n ('unreal', 1),\n ('us', 2),\n ('viruses', 1),\n ('was', 1),\n ('wasnt', 1),\n ('water', 2),\n ('way', 3),\n ('we', 9),\n ('wed', 1),\n ('week', 1),\n ('well', 1),\n ('were', 1),\n ('when', 2),\n ('who', 4),\n ('why', 1),\n ('world', 1),\n ('you', 10),\n ('your', 2)]"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Apply the `word_count_map_function` to each the documents\n",
    "map_output_values = map(word_count_map_function, documents)\n",
    "# Step 2: Merge the outputs of the map function into a single list\n",
    "merged_output_values = reduce(merge_lists_reduce_function, map_output_values)\n",
    "# Step 3: Apply the `word_count_reduce_function` to create a single word/count dictionary\n",
    "counted_words_dict = word_count_reduce_function(merged_output_values)\n",
    "counted_words_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Assignment 3.2\n",
    "\n",
    "The second part of the assignment reproduces the word-count task using  [Apache Spark's resilient distributed dataset (RDD)](https://spark.apache.org/docs/latest/rdd-programming-guide.html). This abstraction allows MapReduce code to run in parallel in the memory of multiple computers.  \n",
    "\n",
    "The following code initializes the Spark application. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"DSC 400 Assignment 3\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark_context = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The next code snippet loads the previously defined `documents` and creates a Spark RDD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Partitions: 32\n"
     ]
    }
   ],
   "source": [
    "documents_rdd = spark_context.parallelize(documents)\n",
    "\n",
    "print(\"Number of Partitions: \"+str(documents_rdd.getNumPartitions()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Spark waits until there is output to execute this code. The `collect` method causes Spark to collect all the elements in the RDD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"\\n    Well, the way they make shows is, they make one show. \\n    That show's called a pilot. \\n    Then they show that show to the people who make shows, \\n    and on the strength of that one show they decide \\n    if they're going to make more shows. Some pilots \\n    get picked and become television programs. \\n    Some don't, become nothing. \\n    She starred in one of the ones that became nothing.\\n\", \"\\n    You think water moves fast? You should see ice. \\n    It moves like it has a mind. \\n    Like it knows it killed the world once and got a taste for murder. \\n    After the avalanche, it took us a week to climb out. \\n    Now, I don't know exactly when we turned on each other, \\n    but I know that seven of us survived the slide... \\n    and only five made it out. Now we took an oath, that I'm breaking now. \\n    We said we'd say it was the snow that killed the other two, but it wasn't. \\n    Nature is lethal but it doesn't hold a candle to man.\\n\", \"\\n    Now that we know who you are, I know who I am. I'm not a mistake! \\n    It all makes sense! In a comic, you know how you can tell who the arch-villain's going to be? \\n    He's the exact opposite of the hero. And most times they're friends, like you and me! \\n    I should've known way back when... You know why, David? Because of the kids. \\n    They called me Mr Glass.\\n\", \"\\n    Your bones don't break, mine do. That's clear. \\n    Your cells react to bacteria and viruses differently than mine. \\n    You don't get sick, I do. That's also clear. \\n    But for some reason, you and I react the exact same way to water. \\n    We swallow it too fast, we choke. We get some in our lungs, we drown. \\n    However unreal it may seem, we are connected, you and I. \\n    We're on the same curve, just on opposite ends.\\n\"]\n"
     ]
    }
   ],
   "source": [
    "documents_rdd_collect = documents_rdd.collect()\n",
    "print(documents_rdd_collect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `flatMap` method applies the `word_count_map_function` to each the documents. Unlike the `map` method, `flatMap` flattens the results into a single collection. Using `flatMap` means there is no need for a second step to merge the multiple results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[('well', 1),\n ('the', 1),\n ('way', 1),\n ('they', 1),\n ('make', 1),\n ('shows', 1),\n ('is', 1),\n ('they', 1),\n ('make', 1),\n ('one', 1),\n ('show', 1),\n ('that', 1),\n ('shows', 1),\n ('called', 1),\n ('a', 1),\n ('pilot', 1),\n ('then', 1),\n ('they', 1),\n ('show', 1),\n ('that', 1),\n ('show', 1),\n ('to', 1),\n ('the', 1),\n ('people', 1),\n ('who', 1),\n ('make', 1),\n ('shows', 1),\n ('and', 1),\n ('on', 1),\n ('the', 1),\n ('strength', 1),\n ('of', 1),\n ('that', 1),\n ('one', 1),\n ('show', 1),\n ('they', 1),\n ('decide', 1),\n ('if', 1),\n ('theyre', 1),\n ('going', 1),\n ('to', 1),\n ('make', 1),\n ('more', 1),\n ('shows', 1),\n ('some', 1),\n ('pilots', 1),\n ('get', 1),\n ('picked', 1),\n ('and', 1),\n ('become', 1),\n ('television', 1),\n ('programs', 1),\n ('some', 1),\n ('dont', 1),\n ('become', 1),\n ('nothing', 1),\n ('she', 1),\n ('starred', 1),\n ('in', 1),\n ('one', 1),\n ('of', 1),\n ('the', 1),\n ('ones', 1),\n ('that', 1),\n ('became', 1),\n ('nothing', 1),\n ('you', 1),\n ('think', 1),\n ('water', 1),\n ('moves', 1),\n ('fast', 1),\n ('you', 1),\n ('should', 1),\n ('see', 1),\n ('ice', 1),\n ('it', 1),\n ('moves', 1),\n ('like', 1),\n ('it', 1),\n ('has', 1),\n ('a', 1),\n ('mind', 1),\n ('like', 1),\n ('it', 1),\n ('knows', 1),\n ('it', 1),\n ('killed', 1),\n ('the', 1),\n ('world', 1),\n ('once', 1),\n ('and', 1),\n ('got', 1),\n ('a', 1),\n ('taste', 1),\n ('for', 1),\n ('murder', 1),\n ('after', 1),\n ('the', 1),\n ('avalanche', 1),\n ('it', 1),\n ('took', 1),\n ('us', 1),\n ('a', 1),\n ('week', 1),\n ('to', 1),\n ('climb', 1),\n ('out', 1),\n ('now', 1),\n ('i', 1),\n ('dont', 1),\n ('know', 1),\n ('exactly', 1),\n ('when', 1),\n ('we', 1),\n ('turned', 1),\n ('on', 1),\n ('each', 1),\n ('other', 1),\n ('but', 1),\n ('i', 1),\n ('know', 1),\n ('that', 1),\n ('seven', 1),\n ('of', 1),\n ('us', 1),\n ('survived', 1),\n ('the', 1),\n ('slide', 1),\n ('and', 1),\n ('only', 1),\n ('five', 1),\n ('made', 1),\n ('it', 1),\n ('out', 1),\n ('now', 1),\n ('we', 1),\n ('took', 1),\n ('an', 1),\n ('oath', 1),\n ('that', 1),\n ('im', 1),\n ('breaking', 1),\n ('now', 1),\n ('we', 1),\n ('said', 1),\n ('wed', 1),\n ('say', 1),\n ('it', 1),\n ('was', 1),\n ('the', 1),\n ('snow', 1),\n ('that', 1),\n ('killed', 1),\n ('the', 1),\n ('other', 1),\n ('two', 1),\n ('but', 1),\n ('it', 1),\n ('wasnt', 1),\n ('nature', 1),\n ('is', 1),\n ('lethal', 1),\n ('but', 1),\n ('it', 1),\n ('doesnt', 1),\n ('hold', 1),\n ('a', 1),\n ('candle', 1),\n ('to', 1),\n ('man', 1),\n ('now', 1),\n ('that', 1),\n ('we', 1),\n ('know', 1),\n ('who', 1),\n ('you', 1),\n ('are', 1),\n ('i', 1),\n ('know', 1),\n ('who', 1),\n ('i', 1),\n ('am', 1),\n ('im', 1),\n ('not', 1),\n ('a', 1),\n ('mistake', 1),\n ('it', 1),\n ('all', 1),\n ('makes', 1),\n ('sense', 1),\n ('in', 1),\n ('a', 1),\n ('comic', 1),\n ('you', 1),\n ('know', 1),\n ('how', 1),\n ('you', 1),\n ('can', 1),\n ('tell', 1),\n ('who', 1),\n ('the', 1),\n ('archvillains', 1),\n ('going', 1),\n ('to', 1),\n ('be', 1),\n ('hes', 1),\n ('the', 1),\n ('exact', 1),\n ('opposite', 1),\n ('of', 1),\n ('the', 1),\n ('hero', 1),\n ('and', 1),\n ('most', 1),\n ('times', 1),\n ('theyre', 1),\n ('friends', 1),\n ('like', 1),\n ('you', 1),\n ('and', 1),\n ('me', 1),\n ('i', 1),\n ('shouldve', 1),\n ('known', 1),\n ('way', 1),\n ('back', 1),\n ('when', 1),\n ('you', 1),\n ('know', 1),\n ('why', 1),\n ('david', 1),\n ('because', 1),\n ('of', 1),\n ('the', 1),\n ('kids', 1),\n ('they', 1),\n ('called', 1),\n ('me', 1),\n ('mr', 1),\n ('glass', 1),\n ('your', 1),\n ('bones', 1),\n ('dont', 1),\n ('break', 1),\n ('mine', 1),\n ('do', 1),\n ('thats', 1),\n ('clear', 1),\n ('your', 1),\n ('cells', 1),\n ('react', 1),\n ('to', 1),\n ('bacteria', 1),\n ('and', 1),\n ('viruses', 1),\n ('differently', 1),\n ('than', 1),\n ('mine', 1),\n ('you', 1),\n ('dont', 1),\n ('get', 1),\n ('sick', 1),\n ('i', 1),\n ('do', 1),\n ('thats', 1),\n ('also', 1),\n ('clear', 1),\n ('but', 1),\n ('for', 1),\n ('some', 1),\n ('reason', 1),\n ('you', 1),\n ('and', 1),\n ('i', 1),\n ('react', 1),\n ('the', 1),\n ('exact', 1),\n ('same', 1),\n ('way', 1),\n ('to', 1),\n ('water', 1),\n ('we', 1),\n ('swallow', 1),\n ('it', 1),\n ('too', 1),\n ('fast', 1),\n ('we', 1),\n ('choke', 1),\n ('we', 1),\n ('get', 1),\n ('some', 1),\n ('in', 1),\n ('our', 1),\n ('lungs', 1),\n ('we', 1),\n ('drown', 1),\n ('however', 1),\n ('unreal', 1),\n ('it', 1),\n ('may', 1),\n ('seem', 1),\n ('we', 1),\n ('are', 1),\n ('connected', 1),\n ('you', 1),\n ('and', 1),\n ('i', 1),\n ('were', 1),\n ('on', 1),\n ('the', 1),\n ('same', 1),\n ('curve', 1),\n ('just', 1),\n ('on', 1),\n ('opposite', 1),\n ('ends', 1)]"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_output_rdd = documents_rdd.flatMap(word_count_map_function)\n",
    "map_output_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, the `reduceByKey` method combines the results by the key (i.e. word). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[('once', 1),\n ('out', 2),\n ('exactly', 1),\n ('im', 2),\n ('pilot', 1),\n ('starred', 1),\n ('snow', 1),\n ('break', 1),\n ('moves', 2),\n ('we', 9),\n ('wed', 1),\n ('clear', 2),\n ('get', 3),\n ('kids', 1),\n ('your', 2),\n ('react', 2),\n ('become', 2),\n ('think', 1),\n ('climb', 1),\n ('only', 1),\n ('was', 1),\n ('hes', 1),\n ('each', 1),\n ('opposite', 2),\n ('most', 1),\n ('picked', 1),\n ('avalanche', 1),\n ('turned', 1),\n ('comic', 1),\n ('ones', 1),\n ('taste', 1),\n ('lethal', 1),\n ('all', 1),\n ('sense', 1),\n ('exact', 2),\n ('mine', 2),\n ('thats', 2),\n ('i', 8),\n ('when', 2),\n ('two', 1),\n ('ends', 1),\n ('that', 8),\n ('a', 7),\n ('knows', 1),\n ('breaking', 1),\n ('makes', 1),\n ('how', 1),\n ('theyre', 2),\n ('television', 1),\n ('just', 1),\n ('for', 2),\n ('survived', 1),\n ('times', 1),\n ('our', 1),\n ('connected', 1),\n ('shows', 4),\n ('to', 7),\n ('nothing', 2),\n ('should', 1),\n ('make', 4),\n ('is', 2),\n ('more', 1),\n ('ice', 1),\n ('world', 1),\n ('after', 1),\n ('week', 1),\n ('shouldve', 1),\n ('mr', 1),\n ('unreal', 1),\n ('they', 5),\n ('decide', 1),\n ('dont', 4),\n ('candle', 1),\n ('not', 1),\n ('back', 1),\n ('sick', 1),\n ('like', 3),\n ('other', 2),\n ('but', 4),\n ('choke', 1),\n ('show', 4),\n ('you', 10),\n ('swallow', 1),\n ('strength', 1),\n ('seven', 1),\n ('than', 1),\n ('well', 1),\n ('called', 2),\n ('going', 2),\n ('because', 1),\n ('bacteria', 1),\n ('viruses', 1),\n ('also', 1),\n ('in', 3),\n ('tell', 1),\n ('glass', 1),\n ('do', 2),\n ('cells', 1),\n ('the', 15),\n ('people', 1),\n ('man', 1),\n ('be', 1),\n ('reason', 1),\n ('way', 3),\n ('know', 6),\n ('slide', 1),\n ('lungs', 1),\n ('on', 4),\n ('if', 1),\n ('see', 1),\n ('can', 1),\n ('me', 2),\n ('of', 5),\n ('water', 2),\n ('now', 4),\n ('an', 1),\n ('oath', 1),\n ('are', 2),\n ('why', 1),\n ('bones', 1),\n ('however', 1),\n ('then', 1),\n ('who', 4),\n ('became', 1),\n ('has', 1),\n ('nature', 1),\n ('hold', 1),\n ('david', 1),\n ('drown', 1),\n ('seem', 1),\n ('programs', 1),\n ('murder', 1),\n ('said', 1),\n ('am', 1),\n ('pilots', 1),\n ('she', 1),\n ('fast', 2),\n ('it', 12),\n ('made', 1),\n ('doesnt', 1),\n ('too', 1),\n ('mind', 1),\n ('killed', 2),\n ('got', 1),\n ('us', 2),\n ('say', 1),\n ('wasnt', 1),\n ('mistake', 1),\n ('archvillains', 1),\n ('known', 1),\n ('may', 1),\n ('and', 9),\n ('differently', 1),\n ('took', 2),\n ('hero', 1),\n ('curve', 1),\n ('one', 3),\n ('some', 4),\n ('five', 1),\n ('friends', 1),\n ('same', 2),\n ('were', 1)]"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_rdd = map_output_rdd.reduceByKey(add)\n",
    "word_count_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Asssignment 3.2.a\n",
    "\n",
    "The `word_count_rdd` variable is an RDD that contains combined word/count pairs. Using this as a starting point, apply [filter](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.filter.html) to create a new RDD that contains entries with word counts greater than four."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <font color=orange>**TODO**</font>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[('we', 9),\n ('i', 8),\n ('that', 8),\n ('a', 7),\n ('to', 7),\n ('they', 5),\n ('you', 10),\n ('the', 15),\n ('know', 6),\n ('of', 5),\n ('it', 12),\n ('and', 9)]"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Calculate `counts_gt_four_rdd` from `word_count_rdd`\n",
    "counts_gt_four_rdd = word_count_rdd.filter(lambda x: x[1]>4)\n",
    "counts_gt_four_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Asssignment 3.2.b\n",
    "\n",
    "Using [sortBy](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.sortBy.html), create an RDD sorted by word count. The RDD should be sorted from greatest to least (i.e. descending values)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <font color=orange>**TODO**</font>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[('the', 15),\n ('it', 12),\n ('you', 10),\n ('we', 9),\n ('and', 9),\n ('i', 8),\n ('that', 8),\n ('a', 7),\n ('to', 7),\n ('know', 6),\n ('they', 5),\n ('of', 5),\n ('shows', 4),\n ('make', 4),\n ('dont', 4),\n ('but', 4),\n ('show', 4),\n ('on', 4),\n ('now', 4),\n ('who', 4),\n ('some', 4),\n ('get', 3),\n ('like', 3),\n ('in', 3),\n ('way', 3),\n ('one', 3),\n ('out', 2),\n ('im', 2),\n ('moves', 2),\n ('clear', 2),\n ('your', 2),\n ('react', 2),\n ('become', 2),\n ('opposite', 2),\n ('exact', 2),\n ('mine', 2),\n ('thats', 2),\n ('when', 2),\n ('theyre', 2),\n ('for', 2),\n ('nothing', 2),\n ('is', 2),\n ('other', 2),\n ('called', 2),\n ('going', 2),\n ('do', 2),\n ('me', 2),\n ('water', 2),\n ('are', 2),\n ('fast', 2),\n ('killed', 2),\n ('us', 2),\n ('took', 2),\n ('same', 2),\n ('once', 1),\n ('exactly', 1),\n ('pilot', 1),\n ('starred', 1),\n ('snow', 1),\n ('break', 1),\n ('wed', 1),\n ('kids', 1),\n ('think', 1),\n ('climb', 1),\n ('only', 1),\n ('was', 1),\n ('hes', 1),\n ('each', 1),\n ('most', 1),\n ('picked', 1),\n ('avalanche', 1),\n ('turned', 1),\n ('comic', 1),\n ('ones', 1),\n ('taste', 1),\n ('lethal', 1),\n ('all', 1),\n ('sense', 1),\n ('two', 1),\n ('ends', 1),\n ('knows', 1),\n ('breaking', 1),\n ('makes', 1),\n ('how', 1),\n ('television', 1),\n ('just', 1),\n ('survived', 1),\n ('times', 1),\n ('our', 1),\n ('connected', 1),\n ('should', 1),\n ('more', 1),\n ('ice', 1),\n ('world', 1),\n ('after', 1),\n ('week', 1),\n ('shouldve', 1),\n ('mr', 1),\n ('unreal', 1),\n ('decide', 1),\n ('candle', 1),\n ('not', 1),\n ('back', 1),\n ('sick', 1),\n ('choke', 1),\n ('swallow', 1),\n ('strength', 1),\n ('seven', 1),\n ('than', 1),\n ('well', 1),\n ('because', 1),\n ('bacteria', 1),\n ('viruses', 1),\n ('also', 1),\n ('tell', 1),\n ('glass', 1),\n ('cells', 1),\n ('people', 1),\n ('man', 1),\n ('be', 1),\n ('reason', 1),\n ('slide', 1),\n ('lungs', 1),\n ('if', 1),\n ('see', 1),\n ('can', 1),\n ('an', 1),\n ('oath', 1),\n ('why', 1),\n ('bones', 1),\n ('however', 1),\n ('then', 1),\n ('became', 1),\n ('has', 1),\n ('nature', 1),\n ('hold', 1),\n ('david', 1),\n ('drown', 1),\n ('seem', 1),\n ('programs', 1),\n ('murder', 1),\n ('said', 1),\n ('am', 1),\n ('pilots', 1),\n ('she', 1),\n ('made', 1),\n ('doesnt', 1),\n ('too', 1),\n ('mind', 1),\n ('got', 1),\n ('say', 1),\n ('wasnt', 1),\n ('mistake', 1),\n ('archvillains', 1),\n ('known', 1),\n ('may', 1),\n ('differently', 1),\n ('hero', 1),\n ('curve', 1),\n ('five', 1),\n ('friends', 1),\n ('were', 1)]"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Calculate `sorted_word_count_rdd` from `word_count_rdd`\n",
    "sorted_word_count_rdd = word_count_rdd.sortBy(lambda x: x[1], ascending=False)\n",
    "sorted_word_count_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Assignment 3.3\n",
    "\n",
    "[Apache Spark's datasets and dataframes](https://spark.apache.org/docs/latest/sql-programming-guide.html#datasets-and-dataframes) provides a programming interface that abstracts away the underlying details associated with MapReduce or RDDs. In this part of the assignment, you will use Spark's dataframes to perform a word count. You will perform additional operations such as filtering and sorting. \n",
    "\n",
    "The following code creates a [Spark dataframe](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/dataframe.html) from the previously defined `word_count_rdd`.  The `printSchema` method prints the schema for the dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- word: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_count_columns = [\"word\", \"count\"]\n",
    "word_count_df = spark.createDataFrame(\n",
    "    data=word_count_rdd, \n",
    "    schema=word_count_columns\n",
    ")\n",
    "word_count_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `show` method will print the dataframe as a table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   word|count|\n",
      "+-------+-----+\n",
      "|   once|    1|\n",
      "|    out|    2|\n",
      "|exactly|    1|\n",
      "|     im|    2|\n",
      "|  pilot|    1|\n",
      "|starred|    1|\n",
      "|   snow|    1|\n",
      "|  break|    1|\n",
      "|  moves|    2|\n",
      "|     we|    9|\n",
      "|    wed|    1|\n",
      "|  clear|    2|\n",
      "|    get|    3|\n",
      "|   kids|    1|\n",
      "|   your|    2|\n",
      "|  react|    2|\n",
      "| become|    2|\n",
      "|  think|    1|\n",
      "|  climb|    1|\n",
      "|   only|    1|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_count_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Assignment 3.3.a\n",
    "\n",
    "Use the [filter](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.filter.html) method to create a new dataframe with word counts greater than four."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <font color=orange>**TODO**</font>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "|  we|    9|\n",
      "|   i|    8|\n",
      "|that|    8|\n",
      "|   a|    7|\n",
      "|  to|    7|\n",
      "|they|    5|\n",
      "| you|   10|\n",
      "| the|   15|\n",
      "|know|    6|\n",
      "|  of|    5|\n",
      "|  it|   12|\n",
      "| and|    9|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create `word_count_filtered` from `word_count_df`\n",
    "\n",
    "word_count_filtered = word_count_df.filter('count > 4')\n",
    "word_count_filtered.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Assignment 3.3.b\n",
    "\n",
    "Use the [sort](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.sort.html) method to create a new dataframe sorted by word count. Sort the word counts from greatest to least (i.e. descending)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <font color=orange>**TODO**</font>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| word|count|\n",
      "+-----+-----+\n",
      "|  the|   15|\n",
      "|   it|   12|\n",
      "|  you|   10|\n",
      "|  and|    9|\n",
      "|   we|    9|\n",
      "|    i|    8|\n",
      "| that|    8|\n",
      "|   to|    7|\n",
      "|    a|    7|\n",
      "| know|    6|\n",
      "|   of|    5|\n",
      "| they|    5|\n",
      "|  but|    4|\n",
      "| show|    4|\n",
      "|shows|    4|\n",
      "|  now|    4|\n",
      "| some|    4|\n",
      "|  who|    4|\n",
      "| dont|    4|\n",
      "|   on|    4|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create `word_count_sorted` from `word_count_df`\n",
    "\n",
    "word_count_sorted = word_count_df.sort('count', ascending=False)\n",
    "word_count_sorted.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Assignment 3.3.c\n",
    "\n",
    "Use the [limit](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.limit.html)\n",
    "method to create a new dataframe that contains the top ten word count values."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <font color=orange>**TODO**</font>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "| the|   15|\n",
      "|  it|   12|\n",
      "| you|   10|\n",
      "|  we|    9|\n",
      "| and|    9|\n",
      "|that|    8|\n",
      "|   i|    8|\n",
      "|   a|    7|\n",
      "|  to|    7|\n",
      "|know|    6|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create `word_count_top_10` from `word_count_sorted`\n",
    "\n",
    "word_count_top_10 = word_count_sorted.limit(10)\n",
    "word_count_top_10.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}